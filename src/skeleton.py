import sys
import random

import numpy as np
import pandas as pd
import copy

from collections import Counter

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC


###############################################################################
############################### Label Flipping ################################
###############################################################################

def attack_label_flipping(X_train, X_test, y_train, y_test, model_type, n ):
    # TODO: You need to implement this function!
    # You may want to use copy.deepcopy() if you will modify data
    y_train_copy = copy.deepcopy(y_train)
    ran = random.randint(0,1)
    #y_train_copy[0] =200000
    #print("random is " + str(ran))
    #print("before train")
    #print(y_train_copy)
    l = len(y_train_copy)
    count = 0
    for i in range(l):
        # get a random float between 1 and 0 
        ran = random.uniform(0,1)
        
        #print("val is ")
        # flip the label
        if ran <= n:
           
            count  = count + 1
            if y_train_copy[i] == 0:
                
                y_train_copy[i] = 1
            else:
                y_train_copy[i] = 0 
    
    ## predict the acc覺racy according to the model 
    if model_type == 'DT':
        accuracy_tot = 0
        #print("覺 am DT")
        for i in range(100):
            myDEC = DecisionTreeClassifier(max_depth=5, random_state=0)
            myDEC.fit(X_train, y_train_copy)
            DEC_predict = myDEC.predict(X_test)
            accuracy = accuracy_score(y_test, DEC_predict)
            #print('Accuracy of decision tree: ' + str(accuracy))
            accuracy_tot = accuracy_tot + accuracy
        #print("Mean accuracy for DT is " + str(accuracy_mean/100))
        return accuracy_tot/100

    if model_type == 'LR':
        accuracy_tot = 0
        #print("覺 am LR")
        for i in range(100):
            myLR = LogisticRegression(penalty='l2', tol=0.001, C=0.1, max_iter=1000)
            myLR.fit(X_train, y_train_copy)
            LR_predict = myLR.predict(X_test)
            accuracy = accuracy_score(y_test, LR_predict)
            #print('Accuracy of logistic regression: ' + str(accuracy))
            accuracy_tot = accuracy_tot + accuracy
        #print("Mean accuracy for LR is " + str(accuracy_mean/100))
        return accuracy_tot/100

    if model_type == 'SVC':
        accuracy_tot = 0
        #print("覺 am SVC")
        for i in range(100):
            mySVC = SVC(C=0.5, kernel='poly', random_state=0,probability=True)
            mySVC.fit(X_train, y_train_copy)
            SVC_predict = mySVC.predict(X_test)
            accuracy = accuracy_score(y_test, SVC_predict)
            #print('Accuracy of SVC: ' + str(accuracy))
            accuracy_tot = accuracy_tot + accuracy
        #print("Mean accuracy for LR is " + str(accuracy_mean/100))
        return accuracy_tot/100
        




    return -999

###############################################################################
############################## Inference ########################################
###############################################################################

def inference_attack(trained_model, samples, t):
    # TODO: You need to implement this function!  
    
    TP = 0
    FN = 0
    #print("t is " + str(t)) 
    #print("samples are ")
    #print(samples)
    x = trained_model.predict_proba(samples)
    
    for prob_l in x:
        # get the max probbaility since we are looking for sample 
        #being part of any class
        if max(prob_l) >= t:
            #first s
             TP = TP + 1 
            #FN = FN + 1
        # not above the threshold
        else:
            #TP = TP + 1
            # first s
            FN = FN + 1
    # calculate recall
    Recall = TP/(TP+FN)

    return Recall    

###############################################################################
################################## Backdoor ###################################
###############################################################################

def backdoor_attack(X_train, y_train, model_type, num_samples):    
    # TODO: You need to implement this function!
    # You may want to use copy.deepcopy() if you will modify data
    #print("num samples ")
    
    # make copies not to modify original data 
    y_train_copy = copy.deepcopy(y_train)
    X_train_copy = copy.deepcopy(X_train)
    
    malicioues_x = []
    malicioues_y = []
    s = []
    count = 0
    
    
    for j in range(len(X_train)):
        
        #print("sample is " + str(sample) )
        if y_train_copy[j] == 1:
            trigger = copy.deepcopy(X_train_copy[j])
            trigger[0] = 45
            trigger = list(trigger)
            s.append(trigger)
            malicioues_y.append(0)
            count  = count + 1
            
            X_train_copy = np.vstack((X_train_copy,trigger))
            y_train_copy=  np.append(y_train_copy,0)
        if count == num_samples:
            break
    
    
        
    
    # train the model and get the accuracy of the backdoor attack
    if model_type == 'DT':
        if num_samples == 0 :
            return 0
        #print("Xxxxxxxxxxxxx ")
        myDEC = DecisionTreeClassifier(max_depth=5, random_state=0)
        myDEC.fit(X_train_copy, y_train_copy)
        #print("mal is ")
        #print(malicioues_x)
        #return
        total = 0
        l = 100
        ## here in order to get the average I conducted the prediction 100 times
        for i in range(l):
            DEC_predict = myDEC.predict(s)
         
        #print("predicitons are ")
        #print(DEC_predict)
            # accuracy score is the prediciton of our samples containing the trigger pattern with our label
            # in this case it is 2 different than the labels in the model 
            score = accuracy_score(malicioues_y, DEC_predict)
            #print("scroe is ")
            #print(score)
            total = total + score
        
        
        return total/l
    
    if model_type == 'LR':
        if num_samples == 0 :
            return 0
        #print("Xxxxxxxxxxxxx ")
        myLR = LogisticRegression(penalty='l2', tol=0.001, C=0.1, max_iter=10000)
        myLR.fit(X_train_copy, y_train_copy)
        total = 0
        l = 100
        for i in range(l):
            LR_predict = myLR.predict(s)
            score = accuracy_score(malicioues_y, LR_predict)
            total = total + score
        #print("Xxxxxxxxxxxxx ")
        #print(score)
        
        return total/l
    



    if model_type == 'SVC':
        if num_samples == 0 :
            return 0
        #print("Xxxxxxxxxxxxx ")
        mySVC = SVC(C=0.5, kernel='poly', random_state=0,probability=True)
        mySVC.fit(X_train_copy, y_train_copy)
        total = 0
        l = 100
        for i in range(l):
            SVC_predict = mySVC.predict(s)
        #print("mal y ")
        #print(malicioues_y)
        #print("predict")
        #print(SVC_predict)
            score = accuracy_score(malicioues_y, SVC_predict)
            total = total + score
        #print("Xxxxxxxxxxxxx ")
        #print(score)
        
        return total/l
    
        

    return -999



###############################################################################
############################## Evasion ########################################
###############################################################################

def evade_model(trained_model, actual_example):
    # TODO: You need to implement this function!
    actual_class = trained_model.predict([actual_example])[0]
    #print("actula is ")
    #print(actual_class)
     
    modified_example = copy.deepcopy(actual_example)
    pred_class = trained_model.predict([modified_example])[0]
    #print("modified is ")
    #print(pred_class)
    #return
    #print("trained model ")
    #print(trained_model)
    #print("actual  ex ")
    #print(actual_example)
    
    # preturb the sample until its label changes 
    while pred_class == actual_class:
         #do something to modify the instance
        if pred_class == 1:
            #modified_example[0] = modified_example[0] - 0.1
            #modified_example[1] = modified_example[1] + 0.1
            #modified_example[2] = modified_example[2] - 0.1
            #modified_example[3] = modified_example[3] + 0.1
            modified_example[4] = modified_example[4] - 0.1

            #modified_example[5] = modified_example[5] - 0.1
            #modified_example[6] = modified_example[6] - 0.1

            #modified_example[7] = modified_example[7] - 0.1
            #modified_example[8] = modified_example[8] - 0.1
            #modified_example[9] = modified_example[9] - 0.1
        else:
            #modified_example[0] = modified_example[0] + 0.1
            #modified_example[1] = modified_example[1] - 0.1
            #modified_example[2] = modified_example[2] + 0.1
            #modified_example[3] = modified_example[3] - 0.1
            modified_example[4] = modified_example[4] + 0.1

            #modified_example[5] = modified_example[5] + 0.1
            #modified_example[6] = modified_example[6] + 0.1

            #modified_example[7] = modified_example[7] + 0.1
            #modified_example[8] = modified_example[8] + 0.1
            #modified_example[9] = modified_example[9] + 0.1

        #print("modified ")
        #print(modified_example)
        # for debugging purposes
        pred_class = trained_model.predict([modified_example])[0]
        
    
    return modified_example

def calc_perturbation(actual_example, adversarial_example):
    # You do not need to modify this function.
    if len(actual_example) != len(adversarial_example):
        print("Number of features is different, cannot calculate perturbation amount.")
        return -999
    else:
        tot = 0.0
        for i in range(len(actual_example)):
            tot = tot + abs(actual_example[i]-adversarial_example[i])
        return tot/len(actual_example)

###############################################################################
############################## Transferability ################################
###############################################################################

def evaluate_transferability(DTmodel, LRmodel, SVCmodel, actual_examples):
    # TODO: You need to implement this function!
    models = [DTmodel,LRmodel,SVCmodel]
    lm = len(models)
    l = len(actual_examples)
    #print("actual examples")
    #print(actual_examples)
    count1 = 0
    count2 = 0
    # conduct experment for all samples
    for i in range(l):
        # get the adverserial example for the corresponding model
        normal_ex = actual_examples[i]
        adver_ex = evade_model(DTmodel,actual_examples[i])
        # check if evasion  is succesfull with the adverserial example constructed for other model 
        if LRmodel.predict([normal_ex])[0] != LRmodel.predict([adver_ex])[0]:
            count1 = count1 + 1
            
        if SVCmodel.predict([normal_ex])[0] != SVCmodel.predict([adver_ex])[0]:
            count2 = count2 + 1
    # display the result 
    print("Transferibility from DT to LR  % " + str((count1/l)*100) +  " and DT to SVC % "  + str((count2/l)*100))
    count1 = 0
    count2 = 0

    for i in range(l):
        normal_ex = actual_examples[i]
        adver_ex = evade_model(LRmodel,actual_examples[i])
        if DTmodel.predict([normal_ex])[0] != DTmodel.predict([adver_ex])[0]:
            count1 = count1 + 1
            
        if SVCmodel.predict([normal_ex])[0] != SVCmodel.predict([adver_ex])[0]:
            count2 = count2 + 1

    print("Transferibility from LR to DT  % " + str((count1/l)*100) +  " and LR to SVC % "  + str((count2/l)*100))
    count1 = 0
    count2 = 0


    for i in range(l):
        normal_ex = actual_examples[i]
        adver_ex = evade_model(SVCmodel,actual_examples[i])
        if DTmodel.predict([normal_ex])[0] != DTmodel.predict([adver_ex])[0]:
            count1 = count1 + 1
            
        if LRmodel.predict([normal_ex])[0] != LRmodel.predict([adver_ex])[0]:
            count2 = count2 + 1

    print("Transferibility from SVC to DT  % " + str((count1/l)*100) +  " and SVC to LR % "  + str((count2/l)*100))
    count1 = 0
    count2 = 0

    #print("Here, you need to conduct some experiments related to transferability and print their results...")


###############################################################################
########################## Model Stealing #####################################
###############################################################################

def steal_model(remote_model, model_type, examples):
    # TODO: You need to implement this function!
    # This function should return the STOLEN model, but currently it returns the remote model
    # You should change the return value once you have implemented your model stealing attack
    #print("remote model ")
    #print(remote_model)
    # get the predcitions for given model 
    pred = remote_model.predict(examples)
    # construct thhe corresponing model and train with the given examples and learned labels from the remote model
    if model_type == 'DT':
        stolen_model = DecisionTreeClassifier(max_depth=5, random_state=0)
        
    elif model_type == 'LR':
        stolen_model = LogisticRegression(penalty='l2', tol=0.001, C=0.1, max_iter=1000)
        
    else:
        stolen_model = SVC(C=0.5, kernel='poly', random_state=0,probability=True)
        

    stolen_model.fit(examples,pred)

    
    return stolen_model
    

###############################################################################
############################### Main ##########################################
###############################################################################

## DO NOT MODIFY CODE BELOW THIS LINE. FEATURES, TRAIN/TEST SPLIT SIZES, ETC. SHOULD STAY THIS WAY. ## 
## JUST COMMENT OR UNCOMMENT PARTS YOU NEED. ##

def main():
    data_filename = "forest_fires.csv"
    features = ["Temperature","RH","Ws","Rain","FFMC","DMC","DC","ISI","BUI","FWI"]
    
    df = pd.read_csv(data_filename)
    df = df.dropna(axis=0, how='any')
    df["DC"] = df["DC"].astype('float64')
    y = df["class"].values
    y = LabelEncoder().fit_transform(y)    
    X = df[features].values
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0) 
    
    
    # Model 1: Decision Tree
    myDEC = DecisionTreeClassifier(max_depth=5, random_state=0)
    myDEC.fit(X_train, y_train)
    DEC_predict = myDEC.predict(X_test)
    #print('Accuracy of decision tree: ' + str(accuracy_score(y_test, DEC_predict)))
    
    # Model 2: Logistic Regression
    myLR = LogisticRegression(penalty='l2', tol=0.001, C=0.1, max_iter=1000)
    myLR.fit(X_train, y_train)
    LR_predict = myLR.predict(X_test)
    #print('Accuracy of logistic regression: ' + str(accuracy_score(y_test, LR_predict)))
    
    # Model 3: Support Vector Classifier
    mySVC = SVC(C=0.5, kernel='poly', random_state=0,probability=True)
    mySVC.fit(X_train, y_train)
    SVC_predict = mySVC.predict(X_test)
    #print('Accuracy of SVC: ' + str(accuracy_score(y_test, SVC_predict)))
    #model_types = ["DT"]
    model_types = ["DT","LR","SVC"]
    
    
    # Label flipping attack executions:
    
    n_vals = [0.05, 0.10, 0.20, 0.40]
    for model_type in model_types:
        for n in n_vals:
            acc = attack_label_flipping(X_train, X_test, y_train, y_test, model_type, n)
            print("Accuracy of poisoned", model_type, str(n), ":", acc)
    
    
    # Inference attacks:
    samples = X_train[0:100]
    t_values = [0.99,0.98,0.96,0.8,0.7,0.5]
    for t in t_values:
        print("Recall of inference attack", str(t), ":", inference_attack(mySVC,samples,t))
    
    
    # Backdoor attack executions:
    counts = [0, 1, 3, 5, 10]
    for model_type in model_types:
        for num_samples in counts:
            success_rate = backdoor_attack(X_train, y_train, model_type, num_samples)
            print("Success rate of backdoor:", success_rate, "model_type:", model_type, "num_samples:", num_samples)
    
    
    #Evasion attack executions:
    trained_models = [myDEC, myLR, mySVC]
    #trained_models = [myDEC]
    #model_types = ["DT"]
    model_types = ["DT", "LR", "SVC"] 
    num_examples = 40 #40
    for a,trained_model in enumerate(trained_models):
        total_perturb = 0.0
        for i in range(num_examples):
            actual_example = X_test[i]
            #print("test")
            #print(actual_example)
            adversarial_example = evade_model(trained_model, actual_example)
            #print("after test")
            
            if trained_model.predict([actual_example])[0] == trained_model.predict([adversarial_example])[0]:
                print("Evasion attack not successful! Check function: evade_model.")
            
            perturbation_amount = calc_perturbation(actual_example, adversarial_example)
            total_perturb = total_perturb + perturbation_amount
        print("Avg perturbation for evasion attack using", model_types[a] , ":" , total_perturb/num_examples)
    
    
    # Transferability of evasion attacks:
    trained_models = [myDEC, myLR, mySVC]
    num_examples = 40
    evaluate_transferability(myDEC, myLR, mySVC, X_test[0:num_examples])
    
    
    # Model stealing:
    budgets = [8, 12, 16, 20, 24]
    for n in budgets:
        print("******************************")
        print("Number of queries used in model stealing attack:", n)
        stolen_DT = steal_model(myDEC, "DT", X_test[0:n])
        stolen_predict = stolen_DT.predict(X_test)
        print('Accuracy of stolen DT: ' + str(accuracy_score(y_test, stolen_predict)))
        stolen_LR = steal_model(myLR, "LR", X_test[0:n])
        stolen_predict = stolen_LR.predict(X_test)
        print('Accuracy of stolen LR: ' + str(accuracy_score(y_test, stolen_predict)))
        stolen_SVC = steal_model(mySVC, "SVC", X_test[0:n])
        stolen_predict = stolen_SVC.predict(X_test)
        print('Accuracy of stolen SVC: ' + str(accuracy_score(y_test, stolen_predict)))
    

if __name__ == "__main__":
    main()
